\documentclass[11pt]{scrartcl}
\usepackage{evan}

\title{Algebraic Combinatorics HW 2}
\author{Evan L, Dallin G, Alexander D, and Sawyer V}
\date{2-13-2024}
\definecolor{palegreen}{rgb}{0.6, 0.98, 0.6}
\begin{document}
\maketitle
\setcounter{section}{1}
\begin{problem}[\textcolor{red}{Random Walks on $\mathbb{Z}$}]
    Consider a random walk on $\mathbb{Z}$ where we start at 0 and move from $i$ to $i + 1$ or $i - 1$ with equal probability.

    \begin{enumerate}[(i)]
        \item Prove that we eventually return to 0 with probability 1.
        \item Compute $a_i$ explicitly and conclude that
        \[
            \sum_{n=0}^{\infty} \frac{a_n}{2^n} = 1
        \]

        What is the sequence ${a_n}$ called in Math literature?
        \item Prove that each number $n$ is visited at least once with probability 1.
        \item Let $H_n$ denote the expected \# steps needed to reach $n$ for the first time. What is wrong with the
        following argument?

        We claim that $H_n = cn$ for some constant $c$. This is true for $n = 0$. So let $n > 0$. On the average, we need $H_1$ steps to reach 1, and then $H_{n-1}$ steps to reach n starting from 1. Hence
        \[
            H_n = H_1 + H_{n-1} = c + c(n-1) = cn ; H_1 = c
        \]
    \end{enumerate}
\end{problem}
%NEEDS CHECKING: ALSO, WHAT IS THIS SEQUENCE CALLED? IS THERE A NICER WAY TO WRITE IT?
\begin{proof}
    \begin{enumerate}[(i)]
        \item Denote the probability that, starting at $a$, we eventually reach $b$, by $P(a\to b)$. Then, notice that our second step either brings us to $\pm 2$ or to $0$. Thus, \[P(0\to 0)=\frac12+\frac12P(2\to 0)=\frac12+\frac12P(2\to1)P(1\to0)=\frac12+\frac12P(1\to 0)^2.\]
        We find $P(1\to0)$ using a similar method as in class:
        \[P(1\to 0)=\frac12+\frac12(P(2\to 0))=\frac12+\frac12 P(1\to0)^2,\] so $P(1\to0)^2-2P(1\to 0)+1=0$, so $P(1\to 0)=1$. Thus, \[P(0\to 0)=\frac12+\frac12=1.\]
        \item We compute $a_i$, the number of $i$-walks from $0$ to $0$. Clearly, if $i$ is odd, $a_{2i+1}=0$. If $i$ is even, then we simply choose $\frac{i}2$ left steps out of $i$ total steps, so $a_{2i}=\dbinom{2i}{i}$. Thus, \[a_n=\dbinom{n}{n/2}\frac{1+(-1)^n}{2}.\] The probability of returning to the origin after $n$ steps is $\frac{a_n}{2^n}$, and since we know we eventually return to the origin, it follows that \[\sum_{n=0}^{\infty}\frac{a_n}{2^n}=1.\]
        \item As shown in part (i), $P(1\to 0)=1$, and by symmetry, $P(0\to 1)=1$. Thus, at some point, we reach $1$. Then, since $P(0\to 1)=P(n\to n+1)$, we will reach $2$ at some point. Noting that $P(n\to n-1)=P(n\to n+1)=1$, we see that we can reach any $n$ at some point wiht probability $1$.
        \item The flaw in this argument is that it fails to calculate $H_1$. Suppose, for the sake of contradiction, that $H_1$ is finite. Then, $H_1=\frac{1}{2}+\frac{1}{2}(H_2+1)$, so \[2H_1=2+2H_1+1,\] which is moderately problematic, and a contradiction. Thus, we cannot say $H_1=c$.
    \end{enumerate}
\end{proof}
\begin{problem}[\textcolor{red}{Some examples of Hitting times}]\phantom{0}

    \begin{enumerate}[(i)]
        \item Find the hitting time between any two vertices of $K_n$.
        \item Find the hitting time between the endpoints of $P_n$ (a path on $n$ vertices).
        \item Find the hitting time between an endpoint of $P_n$ and a vertex at distance $k$ from it.
        \item Find the hitting time between two vertices of $C_n$ (cycle of $n$ vertices) at distance $k$.
        \item Find the hitting time between two `antipodal' vertices of $Q_3$.
    \end{enumerate}
\end{problem}
\begin{proof}
    \begin{enumerate}[(i)]
        \item We exploit unfair labor market conditions. That is, we exploit symmetry in the graph: the hitting time between any two distinct vertices of $K_n$ is the same. Let this hitting time be $x$, then \[x=\frac{1}{n-1}\cdot1+\frac{n-2}{n-1}(x+1),\] whence \[x=(n-1)^2.\]
        \item Label our path with vertices $\{1,2,3,\dots,n\}$. Denote by $c_i$ the expected number of steps to go from vertex $i$ to $i+1$. We build a recursion relation for the $c_i$: \[c_{i}=\frac12\cdot1+\frac12(1+c_{i-1}+c_{i})\] gives \[c_i=2+c_{i-1}.\] Clearly, $c_1=1$, so $c_{i}=2i-1$, and the hitting time between the endpoints of $P_n$, or the hitting time from $1$ to $n$, is \[c_1+c_2+\cdots+c_{n-1}=(n-1)^2.\]
        \item This is simply the sum \[\sum_{i=1}^kc_i=k^2.\]
        \item WLOG we're considering vertices of distance $k$ from $v_1$. For odd $n$, we can take a step and have distance from a vertex unchanged ($v_3$ and $v_4$ are equidistant from $v_1$ on $C_5$). This observation motivates us to consider the graph with vertices $w_i$ that represent distance between our vertex and $v_1$.
        
        For even $n=2a$, we have
        \begin{center}
            \begin{asy}
                size(3cm);
                dot((0,0));
                dot((1,0));
                dot((2,0));
                draw((0,0)--(2,0));
                label("$w_0$",(0,0),S);
                label("$w_1$",(1,0),N);
                label("$w_2$",(2,0),S);
                label("$\dots$",(3,0));
                dot((4,0));
                label("$w_{a-1}$",(4,0),S);
                dot((6,0));
                label("$w_a$",(6,0),S);
                draw((6,0)--(4,0));
            \end{asy}
        \end{center}
        and so wish to find the hitting time between $w_k$ and $w_0$. This is an analogous setup to the previous part, so our hitting time is $k^2$.

        For odd $n=2a+1$,
        \begin{center}
            \begin{asy}
                size(3cm);
                dot((0,0));
                dot((1,0));
                dot((2,0));
                draw((0,0)--(2,0));
                label("$w_0$",(0,0),S);
                label("$w_1$",(1,0),N);
                label("$w_2$",(2,0),S);
                label("$\dots$",(3,0));
                dot((4,0));
                label("$w_{a-1}$",(4,0),S);
                dot((6,0));
                label("$w_{a}$",(6,0),S);
                draw((6,0)--(4,0));
                draw((6,0)--(6.5,0.5));
                draw(arc((7,0),(6.5,-0.5),(6.5,0.5)));
                draw((6,0)--(6.5,-0.5));
            \end{asy}
        \end{center}
        which slightly scuppers attempts to make a direct corollary of part (ii). That said, we can define $c_i$ to be the expected steps between $w_i$ and $w_{i-1}$. Notice that (for $i<a$) \[c_i=\frac12\cdot1+\frac12(1+c_{i+1}+c_i)\implies c_i=2+c_{i+1},\] and as \[c_a=\frac{1}{2}\cdot1+\frac12\cdot(1+c_a)\implies c_a=2,\] $c_i=2+2a-2i$. We compute \[\sum_{i=1}^k c_i=(2+2a)(k)-k(k+1)=k(n-k).\]
        The hitting time is thus: \[\begin{cases}k^2&n\text{ even}\\ k(n-k)&n\text{ odd}\end{cases}.\]
        \item Rather than working with the transition matrix for the hypercube, we represent the hypercube as a random walk along a path where each node represents the hamming distance of the current vertex from the starting vertex. We are guaranteed to move to a vertex with hamming distance of $1$. From there we have a $1/3$ chance of moving back but a $2/3$ chance of moving to a node with hamming distance of $2$.
        \begin{center}
            \begin{asy}
                size(3cm);
                dot((0,0));
                dot((1,0));
                dot((2,0));
                dot((3,0));
                draw((0,0)--(3,0));
                label("$0$",(0,0),S);
                label("$1$",(1,0),S);
                label("$2$",(2,0),S);
                label("$3$",(3,0),S);
                label("$1$",(0.5,0),N);
                label("$1/3$",(1.5,0),N);
                label("$2/3$",(2.5,0),N);
            \end{asy}
        \end{center}

        From these probabilities, we can construct the following transition matrix:
        \[
            M = \begin{pmatrix}
                0 & 1 & 0 & 0\\
                1/3 & 0 & 2/3 & 0\\
                0 & 2/3 & 0 & 1/3\\
                0 & 0 & 1 & 0
            \end{pmatrix}
        \]

        Letting $v$ be the antipodal (fourth) vertex:
        \[
            I - M[v] = \begin{pmatrix}
                1 & -1 & 0\\
                -1/3 & 1 & -2/3\\
                0 & -2/3 & 1
            \end{pmatrix}
        \]
        therefore
        \[
            (I - M[v])^{-2} = \begin{pmatrix}
                16 & 81/2 & 30\\
                27/2 & 36 & 27\\
                10 & 27 & 21
            \end{pmatrix}
        \]
        and thus
        \[
            (I - M[v])^{-2} \begin{pmatrix}
                0\\
                0\\
                1/3
            \end{pmatrix} = \begin{pmatrix}
                10\\
                9\\
                7
            \end{pmatrix}
        \]
        whence
        \[
            H(v_1, v) = 10    
        \]

    \end{enumerate}
\end{proof}
\begin{problem}
    \begin{enumerate}[(i)]
        \item Show that the following may hold for some graphs $G$ (including regular graphs)
        \[H(u,v)\neq H(v,u),\text{ for some }u,v\in V(G).\]
        \item If $u$ and $v$ have the same degree, then the probability that a random walk starting at $u$ vists $v$ before returning to $u$ is equal to the probability that a random walk starting at $v$ vists $u$ before returning to $u$. What can be said if the degrees of $u$ and $v$ are different?
    \end{enumerate}
\end{problem}
\begin{proof}
    \begin{enumerate}[(i)]
        \item Suppose we have a graph in which vertices $v_1$ and $v_3$ each have one loop and are both connected to $v_2$:
        % TO EVAN: Please make this not look like trash
        \begin{center}
            \begin{asy}
                size(3cm);
                dot((0,0));
                dot((1,0));
                dot((2,0));
                draw((0,0)--(2,0));
                label("$v_1$",(0,0),S);
                label("$v_2$",(1,0),S);
                label("$v_3$",(2,0),S);
                draw((2,0)--(2.5,0.5));
                draw(arc((3,0),(2.5,-0.5),(2.5,0.5)));
                draw((2,0)--(2.5,-0.5));

                draw((0,0)--(-0.5,0.5));
                draw(arc((-1,0),(-0.5,0.5),(-0.5,-0.5)));
                draw((0,0)--(-0.5,-0.5));
            \end{asy}
        \end{center}
        The transition matrix for this graph is
        \[
            M = \begin{pmatrix}
                1/2 & 1/2 & 0\\
                1/2 & 0 & 1/2\\
                0 & 1/2 & 1/2
            \end{pmatrix}
        \]
        and the hitting times towards $v_2$ are
        \[
            H(v_1, v_2) = H(v_3, v_2) = 2.  
        \]

        These, however, do not match the hitting times approaching $v_1$:
        \[
            H(v_2, v_1) = 4 \neq H(v_2, v_3) = 2.
        \]

        Therefore, we have found a graph for which $H(u,v) \neq H(v,u)$ for some $u,v \in V(G)$.

    \end{enumerate}
\end{proof}
\end{document}
